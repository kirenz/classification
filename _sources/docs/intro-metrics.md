# Performance metrics

## Accuracy

Accuracy is one metric for evaluating classification models:

- Read: [Accuracy](https://developers.google.com/machine-learning/crash-course/classification/accuracy?hl=en)

## Precision and recall


Learn about precision and recall:

- Read: [Precision and Recall](https://developers.google.com/machine-learning/crash-course/classification/precision-and-recall?hl=en)

Next, check your understanding by answering [this questions about Accuracy, Precision and Recall)](https://developers.google.com/machine-learning/crash-course/classification/check-your-understanding-accuracy-precision-recall?hl=en)

Read the interactive article [Attacking discrimination with smarter machine learning](https://research.google.com/bigpicture/attacking-discrimination-in-ml/) to get a better understanding of the relevance of thresholds in classification problems.

## ROC and AUC

An ROC curve (receiver operating characteristic curve) is a graph showing the performance of a classification model at all classification thresholds.

- Read: [ROC Curve and AUC](https://developers.google.com/machine-learning/crash-course/classification/roc-and-auc?hl=en)

Check your understanding: [ROC and AUC](https://developers.google.com/machine-learning/crash-course/classification/check-your-understanding-roc-and-auc?hl=en)